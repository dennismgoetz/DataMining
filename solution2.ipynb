{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankroutesfordriver(driverdata3, rank_routes1, prints=False):\n",
    "    from datasketch import MinHash, MinHashLSH\n",
    "    \n",
    "    def convert_frozensets_to_string(input_set):\n",
    "        result_set = set()\n",
    "        for element in input_set:\n",
    "            if isinstance(element, frozenset):\n",
    "                for i, merch in enumerate(element):\n",
    "                    if i==0:\n",
    "                        result_string=merch\n",
    "                    else:\n",
    "                        result_string += \"-\"+str(merch)\n",
    "                result_set.add(result_string)\n",
    "            else:\n",
    "                result_set.add(element)\n",
    "        return result_set\n",
    "\n",
    "    def create_minhash(set_data, numperm4):\n",
    "        minhash = MinHash(num_perm=numperm4)\n",
    "        for item in set_data:\n",
    "            minhash.update(item.encode('utf-8'))\n",
    "        return minhash\n",
    "\n",
    "    def calculate_jaccard_similarity(minhash1, minhash2):\n",
    "        return minhash1.jaccard(minhash2)\n",
    "\n",
    "    def route_to_minhash(data1, mapborders, num_perm5):\n",
    "        #0add the single cities\n",
    "        #1add the conn between cities\n",
    "        #2add single merch\n",
    "        #3add the merch with binned quantities (s, m, l)\n",
    "        #4add the conn between cities with the product\n",
    "        #5combine \"from\" city with product and \"to\" city with product (without adding from or to)\n",
    "        #6combine products with every other product within a specific trip \n",
    "\n",
    "        #add all the generated sets to a minhashing list\n",
    "        minhash_list=[]\n",
    "        \n",
    "        for route in data1:\n",
    "            vector=set()\n",
    "            for trip in route[\"route\"]:\n",
    "                #0:\n",
    "                vector.update([trip[\"from\"],trip[\"to\"]])\n",
    "                #1:\n",
    "                vector.update([trip[\"from\"]+\"-\"+trip[\"to\"]])\n",
    "                for merch in trip[\"merchandise\"]:\n",
    "                    #2:\n",
    "                    vector.update([merch])\n",
    "                    #3:\n",
    "                    if mapborders[merch][0]==0:\n",
    "                            vector.update([merch+\"-\"+\"medium\"])\n",
    "                    else:\n",
    "                        if trip[\"merchandise\"][merch]<mapborders[merch][0]:\n",
    "                            vector.update([merch+\"-\"+\"small\"])\n",
    "                        elif trip[\"merchandise\"][merch]>mapborders[merch][1]:\n",
    "                            vector.update([merch+\"-\"+\"large\"])\n",
    "                        else:\n",
    "                            vector.update([merch+\"-\"+\"medium\"])\n",
    "                    #4:\n",
    "                    vector.update([trip[\"from\"]+\"-\"+trip[\"to\"]+\"-\"+merch])\n",
    "                    #5:\n",
    "                    vector.update([trip[\"from\"]+\"-\"+merch, trip[\"to\"]+\"-\"+merch])\n",
    "                    #6\n",
    "                    for comb in trip[\"merchandise\"]:\n",
    "                        if comb != merch:\n",
    "                            vector.add(frozenset((comb, merch)))\n",
    "            #first normalise the vector to set elements or tuples\n",
    "            vector=convert_frozensets_to_string(vector)\n",
    "            #then add the set to the minhash_list with the reference actual route\n",
    "            minhash_list.append([route[\"id\"], create_minhash(vector, num_perm5)])\n",
    "        return minhash_list\n",
    "    \n",
    "    def space_borders(data):\n",
    "        #find vector dimensions for combination merchandise and the amount that is carried on that route where \n",
    "        #the amount is specified by a indicator (small, medium, large)\n",
    "        #to do that the max and min is found for every merchandise\n",
    "\n",
    "        #find min and max for a merch and the possible merch to be carried \n",
    "        mapminmax={}\n",
    "        possiblecomb={}\n",
    "\n",
    "        for route in data:\n",
    "            for trip in route[\"route\"]:\n",
    "                for merch in trip[\"merchandise\"]:\n",
    "                    if merch+\"-min\" in mapminmax:\n",
    "                        mapminmax[merch+\"-min\"]=min(mapminmax[merch+\"-min\"], trip[\"merchandise\"][merch])\n",
    "                    else:\n",
    "                        mapminmax[merch+\"-min\"]= trip[\"merchandise\"][merch]\n",
    "                    if merch+\"-max\" in mapminmax:\n",
    "                        mapminmax[merch+\"-max\"]=max(mapminmax[merch+\"-max\"], trip[\"merchandise\"][merch])\n",
    "                    else:\n",
    "                        mapminmax[merch+\"-max\"]= trip[\"merchandise\"][merch]\n",
    "                    \n",
    "                    if merch in possiblecomb:\n",
    "                        possiblecomb[merch]=possiblecomb[merch]+1\n",
    "                    else:\n",
    "                        possiblecomb[merch]=1\n",
    "\n",
    "        #determine borders for dividing range into partitions\n",
    "        mapborders={}\n",
    "\n",
    "        for item in possiblecomb:\n",
    "            if possiblecomb[item]>1:\n",
    "                smallmediumborder=mapminmax[item+\"-\"+\"min\"]+((1/3)*(mapminmax[item+\"-\"+\"max\"]-mapminmax[item+\"-\"+\"min\"]))\n",
    "                mediumlargeborder=mapminmax[item+\"-\"+\"min\"]+((2/3)*(mapminmax[item+\"-\"+\"max\"]-mapminmax[item+\"-\"+\"min\"]))\n",
    "                mapborders[item]=[smallmediumborder, mediumlargeborder]\n",
    "            else:\n",
    "                mapborders[item]=[0]\n",
    "                \n",
    "        return mapborders\n",
    "\n",
    "    def rank_routes(minhaslistdata, minhashlistroutes):\n",
    "        score1=[]\n",
    "        for routes1 in minhashlistroutes:\n",
    "            summation=0.0\n",
    "            for routes2 in minhaslistdata:\n",
    "                summation=summation+calculate_jaccard_similarity(routes1[1], routes2[1])\n",
    "            score1.append([routes1[0], summation/len(minhaslistdata)])\n",
    "        score1=sorted(score1, key=lambda x: x[1], reverse=True)\n",
    "        return score1\n",
    "\n",
    "    numperm3=128\n",
    "    \n",
    "    if(prints==True): print(\"map borders\")\n",
    "    mapborders=space_borders(driverdata3+rank_routes1)\n",
    "    \n",
    "    if(prints==True): print(\"convert routes into minhash signatures\")\n",
    "    minhash_list_data1=route_to_minhash(driverdata3, mapborders, numperm3)\n",
    "    minhash_list_rankroutes1=route_to_minhash(rank_routes1, mapborders, numperm3)\n",
    "        \n",
    "    if(prints==True): print(\"Compare using jaccard\")\n",
    "    result=rank_routes(minhash_list_data1, minhash_list_rankroutes1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data\n",
      "rankroutes\n",
      "map borders\n",
      "convert routes into minhash signatures\n",
      "Compare using jaccard\n",
      "[['s16', 0.16987541333530748], ['s6', 0.16868013399466983], ['s18', 0.1637895136215576], ['s3', 0.15531922441022603], ['s17', 0.15181204348040667], ['s1', 0.14326772406475174], ['s12', 0.142796552660152], ['s13', 0.14151336245188037], ['s11', 0.1378218771592143], ['s8', 0.13562102087651762], ['s7', 0.12584749160991018], ['s10', 0.12578117288520382], ['s20', 0.12342685815812851], ['s15', 0.12058517791925773], ['s4', 0.10882285805942157], ['s14', 0.10830156203731123], ['s9', 0.10795608775046886], ['s19', 0.10302074079557792], ['s2', 0.10202673107294442], ['s5', 0.08865579656499852]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data4 = json.load(file)\n",
    "    return data4\n",
    "\n",
    "print(\"load data\")\n",
    "#load driverdata\n",
    "file_name_driver = \"./data/actual.json\"\n",
    "driver_data=load_data(file_name_driver)\n",
    "\n",
    "#load routes to be ranked\n",
    "file_name_rroutes = \"./data/standard.json\"\n",
    "rank_routes=load_data(file_name_rroutes)\n",
    "\n",
    "driver_data1=[]\n",
    "for route in driver_data:\n",
    "    if route[\"driver\"]==\"I\":\n",
    "        driver_data1.append(route)\n",
    "\n",
    "print(\"rankroutes\")\n",
    "result=rankroutesfordriver(driver_data1, rank_routes, prints=True)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
